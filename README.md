[kaggle-dataset]: https://www.kaggle.com/rmisra/news-category-dataset

# news-analyzer

![cicd](https://github.com/Veetaha/vee-news-analyzer/workflows/cicd/badge.svg)

[![badge](https://img.shields.io/badge/docs-master-blue.svg)](https://veetaha.github.io/vee-news-analyzer/vna/)


This is my university course work for database classes.

The project uses [Kaggle news dataset](kaggle-dataset).

The core of the project is `vna` cli.
It reads the provided **`200K+`** articles from the data source and puts them into thes [`Elasticsearch`](https://github.com/elastic/elasticsearch) cluster while analyzing
the obtained textual information sentiment.
The ingest process is implemented by `vna_data_sync` component.
After this process is done you can use `vna` cli to do fulltext search,
query significant words statistics and news sentiments using various `Elasticsearch`
analysis and query APIs.

# Example analytics

## Significant words

Generated by:

```bash
vna significant-words study
```

![significant_words](https://user-images.githubusercontent.com/36276403/82747264-e4128000-9d9f-11ea-8a96-4b167013dc13.png)

# Bootstrap

## Elasticsearch and Kibana

Deploy local `Elasticsearch` cluster on your local machine, also
spin up a `Kibana` instance with auth-less access to that cluster.
```bash
# Deploy 3-data-nodes cluster
docker-compose -f docker-compose-multi-node.yml up
# Deploy single-node cluster (best for development, otherwise Java will eat your RAM)
docker-compose up
```
The configuration tweaks for the setup are available in `.env` file.
You should create it similar to the provided `EXAMPLE.env` template.

## Cli

Build the cli. The self-contained executable will be avaialbe at `./target/debug/vna`

```bash
cargo build
```

Build and run the cli ingest process. Be sure to put the [kaggle dataset](kaggle-dataset)
at `./datasets/kaggle/news_v2.json` or anywhere else (just make sure that `--kaggle-path`
points to it).

```bash
cargo run -p vna -- data-sync
```
